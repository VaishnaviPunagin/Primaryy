{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VaishnaviPunagin/Primaryy/blob/master/Resnet50%2BHSV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGbPTHAp15lx"
      },
      "source": [
        ""
      ],
      "id": "nGbPTHAp15lx"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "820e1c55",
        "outputId": "360a90ca-c8ce-4a1b-bc8e-2e3998387243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "820e1c55"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-S0zFYAaZFs-"
      },
      "outputs": [],
      "source": [
        "training_ds_path=\"/content/drive/MyDrive/BrainTumor/HSV/Training\"\n",
        "testing_ds_path=\"/content/drive/MyDrive/BrainTumor/HSV/Testing\""
      ],
      "id": "-S0zFYAaZFs-"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5kk_Us03YykP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "5kk_Us03YykP"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ae82cd90"
      },
      "outputs": [],
      "source": [
        "mean=[23.4081, 23.4081, 23.4081]\n",
        "std=[22.4781, 22.4781, 22.4781]\n",
        "\n",
        "train_transforms=transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(90),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(torch.Tensor(mean),torch.Tensor(std))\n",
        "])\n",
        "\n",
        "test_transforms=transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(torch.Tensor(mean),torch.Tensor(std))\n",
        "])"
      ],
      "id": "ae82cd90"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d2ee8f88"
      },
      "outputs": [],
      "source": [
        "train_dataset=torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/BrainTumor/HSV/Training',transform=train_transforms)\n",
        "test_dataset=torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/BrainTumor/HSV/Testing',transform=test_transforms)"
      ],
      "id": "d2ee8f88"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "14dbd02e"
      },
      "outputs": [],
      "source": [
        " def show_transformed_images(dataset):\n",
        "        loader=torch.utils.data.DataLoader(dataset,batch_size=6,shuffle=True)\n",
        "        batch=next(iter(loader))\n",
        "        images,labels=batch\n",
        "        \n",
        "        grid=torchvision.utils.make_grid(images,nrow=3)\n",
        "        plt.figure(figsize=(11,11))\n",
        "        plt.imshow(np.transpose(grid,(1,2,0)))\n",
        "        print('labels:',labels)"
      ],
      "id": "14dbd02e"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "ca1ed9f6",
        "outputId": "54c794fd-9e47-40ed-8ad4-14c46a8bc653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels: tensor([3, 0, 3, 1, 0, 2])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x792 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        " show_transformed_images(train_dataset)"
      ],
      "id": "ca1ed9f6"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b66d9ded"
      },
      "outputs": [],
      "source": [
        "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=32,shuffle=True)\n",
        "test_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=32,shuffle=False)"
      ],
      "id": "b66d9ded"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fb35109"
      },
      "outputs": [],
      "source": [
        "#Completed preprocessing, we'll start models implementation after thisu\n",
        "#mini batch gradient descent will be applied if we mention the mini batch size~"
      ],
      "id": "3fb35109"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6222c29c"
      },
      "outputs": [],
      "source": [
        "def set_device():\n",
        "    if torch.cuda.is_available():\n",
        "        dev=\"cuda:0\"\n",
        "    else:\n",
        "        dev=\"cpu\"\n",
        "    return torch.device(dev)"
      ],
      "id": "6222c29c"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "db03ae0e"
      },
      "outputs": [],
      "source": [
        "def train_nn(model,train_loader,test_loader,criterion,optimizer,n_epochs):\n",
        "    device=set_device()\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch number %d\"%(epoch+1))\n",
        "        model.train()\n",
        "        running_loss=0.0\n",
        "        running_correct=0.0\n",
        "        total=0\n",
        "        \n",
        "        for data in train_loader:\n",
        "            images, labels=data\n",
        "            images=images.to(device)\n",
        "            labels=labels.to(device)\n",
        "            total+=labels.size(0)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs=model(images)\n",
        "            \n",
        "            _,predicted=torch.max(outputs.data,1)\n",
        "            \n",
        "            loss=criterion(outputs,labels)\n",
        "            \n",
        "            loss.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss+=loss.item()\n",
        "            \n",
        "            running_correct+=(labels==predicted).sum().item()\n",
        "            \n",
        "        epoch_loss=running_loss/len(train_loader)\n",
        "        epoch_acc=100.00*running_correct/total\n",
        "        \n",
        "        print(\" -Training DS. Got %d out of %d images correctly (%.3f%%). Epoch  loss: %.3f\" \n",
        "              % (running_correct,total,epoch_acc, epoch_loss))\n",
        "        \n",
        "        evaluate_model_on_test_set(model,test_loader)\n",
        "        \n",
        "    print(\"Finished\")\n",
        "    return model"
      ],
      "id": "db03ae0e"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "17a43e06"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_on_test_set(model,test_loader):\n",
        "    model.eval()\n",
        "    predicted_correctly_on_epoch=0\n",
        "    total=0\n",
        "    device=set_device()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels=data\n",
        "            images=images.to(device)\n",
        "            labels=labels.to(device)\n",
        "            total+=labels.size(0) \n",
        "            \n",
        "            outputs=model(images)\n",
        "            \n",
        "            _,predicted=torch.max(outputs.data,1)\n",
        "            \n",
        "            predicted_correctly_on_epoch += (predicted ==labels).sum().item()\n",
        "            \n",
        "    epoch_acc=100.0*predicted_correctly_on_epoch/total\n",
        "    print(\" -Testing DS. Got %d out of %d images correctly (%.3f%%)\" \n",
        "              % (predicted_correctly_on_epoch,total,epoch_acc))"
      ],
      "id": "17a43e06"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "80e1f8d7"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "resnet50_model=models.resnet50(pretrained=False)\n",
        "num_ftrs=resnet50_model.fc.in_features\n",
        "number_of_classes=4\n",
        "#now we take above 2 vars & in nn.linear-linear is the function that takes number of i/p & o/p features as parameters and \n",
        "#prepares required matrices for forward propagation\n",
        "resnet50_model.fc=nn.Linear(num_ftrs,number_of_classes)\n",
        "device=set_device()\n",
        "resnet_50_model=resnet50_model.to(device)\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "#using stochastic gradient descent for optimizer\n",
        "optimizer=optim.SGD(resnet50_model.parameters(),lr=0.01,momentum=0.9,weight_decay=0.003)"
      ],
      "id": "80e1f8d7"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "V6p9mYsZ_PJo",
        "outputId": "a27eb51f-547c-4b8e-c5e1-35605dcd178f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch number 1\n",
            " -Training DS. Got 738 out of 2870 images correctly (25.714%). Epoch  loss: 4.100\n",
            " -Testing DS. Got 827 out of 2870 images correctly (28.815%)\n",
            "Epoch number 2\n",
            " -Training DS. Got 837 out of 2870 images correctly (29.164%). Epoch  loss: 1.412\n",
            " -Testing DS. Got 826 out of 2870 images correctly (28.780%)\n",
            "Epoch number 3\n",
            " -Training DS. Got 829 out of 2870 images correctly (28.885%). Epoch  loss: 1.408\n",
            " -Testing DS. Got 826 out of 2870 images correctly (28.780%)\n",
            "Epoch number 4\n",
            " -Training DS. Got 975 out of 2870 images correctly (33.972%). Epoch  loss: 1.319\n",
            " -Testing DS. Got 970 out of 2870 images correctly (33.798%)\n",
            "Epoch number 5\n",
            " -Training DS. Got 1060 out of 2870 images correctly (36.934%). Epoch  loss: 1.304\n",
            " -Testing DS. Got 888 out of 2870 images correctly (30.941%)\n",
            "Epoch number 6\n",
            " -Training DS. Got 1190 out of 2870 images correctly (41.463%). Epoch  loss: 1.219\n",
            " -Testing DS. Got 854 out of 2870 images correctly (29.756%)\n",
            "Epoch number 7\n",
            " -Training DS. Got 1366 out of 2870 images correctly (47.596%). Epoch  loss: 1.155\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 8\n",
            " -Training DS. Got 1588 out of 2870 images correctly (55.331%). Epoch  loss: 1.052\n",
            " -Testing DS. Got 827 out of 2870 images correctly (28.815%)\n",
            "Epoch number 9\n",
            " -Training DS. Got 1700 out of 2870 images correctly (59.233%). Epoch  loss: 0.964\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 10\n",
            " -Training DS. Got 1763 out of 2870 images correctly (61.429%). Epoch  loss: 0.915\n",
            " -Testing DS. Got 831 out of 2870 images correctly (28.955%)\n",
            "Epoch number 11\n",
            " -Training DS. Got 1789 out of 2870 images correctly (62.334%). Epoch  loss: 0.893\n",
            " -Testing DS. Got 776 out of 2870 images correctly (27.038%)\n",
            "Epoch number 12\n",
            " -Training DS. Got 1865 out of 2870 images correctly (64.983%). Epoch  loss: 0.831\n",
            " -Testing DS. Got 826 out of 2870 images correctly (28.780%)\n",
            "Epoch number 13\n",
            " -Training DS. Got 1913 out of 2870 images correctly (66.655%). Epoch  loss: 0.777\n",
            " -Testing DS. Got 381 out of 2870 images correctly (13.275%)\n",
            "Epoch number 14\n",
            " -Training DS. Got 1966 out of 2870 images correctly (68.502%). Epoch  loss: 0.748\n",
            " -Testing DS. Got 996 out of 2870 images correctly (34.704%)\n",
            "Epoch number 15\n",
            " -Training DS. Got 2027 out of 2870 images correctly (70.627%). Epoch  loss: 0.709\n",
            " -Testing DS. Got 342 out of 2870 images correctly (11.916%)\n",
            "Epoch number 16\n",
            " -Training DS. Got 2065 out of 2870 images correctly (71.951%). Epoch  loss: 0.702\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 17\n",
            " -Training DS. Got 2020 out of 2870 images correctly (70.383%). Epoch  loss: 0.714\n",
            " -Testing DS. Got 325 out of 2870 images correctly (11.324%)\n",
            "Epoch number 18\n",
            " -Training DS. Got 2067 out of 2870 images correctly (72.021%). Epoch  loss: 0.678\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 19\n",
            " -Training DS. Got 2061 out of 2870 images correctly (71.812%). Epoch  loss: 0.664\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 20\n",
            " -Training DS. Got 2119 out of 2870 images correctly (73.833%). Epoch  loss: 0.644\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 21\n",
            " -Training DS. Got 2143 out of 2870 images correctly (74.669%). Epoch  loss: 0.628\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 22\n",
            " -Training DS. Got 2136 out of 2870 images correctly (74.425%). Epoch  loss: 0.614\n",
            " -Testing DS. Got 834 out of 2870 images correctly (29.059%)\n",
            "Epoch number 23\n",
            " -Training DS. Got 2177 out of 2870 images correctly (75.854%). Epoch  loss: 0.582\n",
            " -Testing DS. Got 2115 out of 2870 images correctly (73.693%)\n",
            "Epoch number 24\n",
            " -Training DS. Got 2213 out of 2870 images correctly (77.108%). Epoch  loss: 0.550\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 25\n",
            " -Training DS. Got 2266 out of 2870 images correctly (78.955%). Epoch  loss: 0.520\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 26\n",
            " -Training DS. Got 2263 out of 2870 images correctly (78.850%). Epoch  loss: 0.525\n",
            " -Testing DS. Got 1399 out of 2870 images correctly (48.746%)\n",
            "Epoch number 27\n",
            " -Training DS. Got 2250 out of 2870 images correctly (78.397%). Epoch  loss: 0.519\n",
            " -Testing DS. Got 896 out of 2870 images correctly (31.220%)\n",
            "Epoch number 28\n",
            " -Training DS. Got 2341 out of 2870 images correctly (81.568%). Epoch  loss: 0.489\n",
            " -Testing DS. Got 577 out of 2870 images correctly (20.105%)\n",
            "Epoch number 29\n",
            " -Training DS. Got 2309 out of 2870 images correctly (80.453%). Epoch  loss: 0.513\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 30\n",
            " -Training DS. Got 2355 out of 2870 images correctly (82.056%). Epoch  loss: 0.450\n",
            " -Testing DS. Got 2136 out of 2870 images correctly (74.425%)\n",
            "Epoch number 31\n",
            " -Training DS. Got 2410 out of 2870 images correctly (83.972%). Epoch  loss: 0.430\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 32\n",
            " -Training DS. Got 2424 out of 2870 images correctly (84.460%). Epoch  loss: 0.403\n",
            " -Testing DS. Got 444 out of 2870 images correctly (15.470%)\n",
            "Epoch number 33\n",
            " -Training DS. Got 2482 out of 2870 images correctly (86.481%). Epoch  loss: 0.356\n",
            " -Testing DS. Got 848 out of 2870 images correctly (29.547%)\n",
            "Epoch number 34\n",
            " -Training DS. Got 2471 out of 2870 images correctly (86.098%). Epoch  loss: 0.369\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 35\n",
            " -Training DS. Got 2529 out of 2870 images correctly (88.118%). Epoch  loss: 0.336\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 36\n",
            " -Training DS. Got 2475 out of 2870 images correctly (86.237%). Epoch  loss: 0.352\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 37\n",
            " -Training DS. Got 2560 out of 2870 images correctly (89.199%). Epoch  loss: 0.292\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 38\n",
            " -Training DS. Got 2553 out of 2870 images correctly (88.955%). Epoch  loss: 0.302\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 39\n",
            " -Training DS. Got 2593 out of 2870 images correctly (90.348%). Epoch  loss: 0.274\n",
            " -Testing DS. Got 826 out of 2870 images correctly (28.780%)\n",
            "Epoch number 40\n",
            " -Training DS. Got 2560 out of 2870 images correctly (89.199%). Epoch  loss: 0.300\n",
            " -Testing DS. Got 530 out of 2870 images correctly (18.467%)\n",
            "Epoch number 41\n",
            " -Training DS. Got 2603 out of 2870 images correctly (90.697%). Epoch  loss: 0.258\n",
            " -Testing DS. Got 842 out of 2870 images correctly (29.338%)\n",
            "Epoch number 42\n",
            " -Training DS. Got 2637 out of 2870 images correctly (91.882%). Epoch  loss: 0.240\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 43\n",
            " -Training DS. Got 2604 out of 2870 images correctly (90.732%). Epoch  loss: 0.257\n",
            " -Testing DS. Got 394 out of 2870 images correctly (13.728%)\n",
            "Epoch number 44\n",
            " -Training DS. Got 2608 out of 2870 images correctly (90.871%). Epoch  loss: 0.249\n",
            " -Testing DS. Got 828 out of 2870 images correctly (28.850%)\n",
            "Epoch number 45\n",
            " -Training DS. Got 2657 out of 2870 images correctly (92.578%). Epoch  loss: 0.225\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 46\n",
            " -Training DS. Got 2656 out of 2870 images correctly (92.544%). Epoch  loss: 0.217\n",
            " -Testing DS. Got 842 out of 2870 images correctly (29.338%)\n",
            "Epoch number 47\n",
            " -Training DS. Got 2682 out of 2870 images correctly (93.449%). Epoch  loss: 0.190\n",
            " -Testing DS. Got 827 out of 2870 images correctly (28.815%)\n",
            "Epoch number 48\n",
            " -Training DS. Got 2612 out of 2870 images correctly (91.010%). Epoch  loss: 0.243\n",
            " -Testing DS. Got 826 out of 2870 images correctly (28.780%)\n",
            "Epoch number 49\n",
            " -Training DS. Got 2642 out of 2870 images correctly (92.056%). Epoch  loss: 0.216\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 50\n",
            " -Training DS. Got 2661 out of 2870 images correctly (92.718%). Epoch  loss: 0.207\n",
            " -Testing DS. Got 908 out of 2870 images correctly (31.638%)\n",
            "Epoch number 51\n",
            " -Training DS. Got 2660 out of 2870 images correctly (92.683%). Epoch  loss: 0.200\n",
            " -Testing DS. Got 394 out of 2870 images correctly (13.728%)\n",
            "Epoch number 52\n",
            " -Training DS. Got 2644 out of 2870 images correctly (92.125%). Epoch  loss: 0.217\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 53\n",
            " -Training DS. Got 2645 out of 2870 images correctly (92.160%). Epoch  loss: 0.229\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 54\n",
            " -Training DS. Got 2655 out of 2870 images correctly (92.509%). Epoch  loss: 0.209\n",
            " -Testing DS. Got 371 out of 2870 images correctly (12.927%)\n",
            "Epoch number 55\n",
            " -Training DS. Got 2619 out of 2870 images correctly (91.254%). Epoch  loss: 0.233\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 56\n",
            " -Training DS. Got 2666 out of 2870 images correctly (92.892%). Epoch  loss: 0.198\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 57\n",
            " -Training DS. Got 2637 out of 2870 images correctly (91.882%). Epoch  loss: 0.228\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 58\n",
            " -Training DS. Got 2658 out of 2870 images correctly (92.613%). Epoch  loss: 0.211\n",
            " -Testing DS. Got 826 out of 2870 images correctly (28.780%)\n",
            "Epoch number 59\n",
            " -Training DS. Got 2669 out of 2870 images correctly (92.997%). Epoch  loss: 0.192\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 60\n",
            " -Training DS. Got 2641 out of 2870 images correctly (92.021%). Epoch  loss: 0.220\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 61\n",
            " -Training DS. Got 2686 out of 2870 images correctly (93.589%). Epoch  loss: 0.176\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 62\n",
            " -Training DS. Got 2644 out of 2870 images correctly (92.125%). Epoch  loss: 0.214\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 63\n",
            " -Training DS. Got 2681 out of 2870 images correctly (93.415%). Epoch  loss: 0.189\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 64\n",
            " -Training DS. Got 2653 out of 2870 images correctly (92.439%). Epoch  loss: 0.203\n",
            " -Testing DS. Got 942 out of 2870 images correctly (32.822%)\n",
            "Epoch number 65\n",
            " -Training DS. Got 2696 out of 2870 images correctly (93.937%). Epoch  loss: 0.185\n",
            " -Testing DS. Got 461 out of 2870 images correctly (16.063%)\n",
            "Epoch number 66\n",
            " -Training DS. Got 2687 out of 2870 images correctly (93.624%). Epoch  loss: 0.177\n",
            " -Testing DS. Got 826 out of 2870 images correctly (28.780%)\n",
            "Epoch number 67\n",
            " -Training DS. Got 2676 out of 2870 images correctly (93.240%). Epoch  loss: 0.180\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 68\n",
            " -Training DS. Got 2672 out of 2870 images correctly (93.101%). Epoch  loss: 0.185\n",
            " -Testing DS. Got 1369 out of 2870 images correctly (47.700%)\n",
            "Epoch number 69\n",
            " -Training DS. Got 2664 out of 2870 images correctly (92.822%). Epoch  loss: 0.188\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 70\n",
            " -Training DS. Got 2690 out of 2870 images correctly (93.728%). Epoch  loss: 0.166\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 71\n",
            " -Training DS. Got 2696 out of 2870 images correctly (93.937%). Epoch  loss: 0.164\n",
            " -Testing DS. Got 826 out of 2870 images correctly (28.780%)\n",
            "Epoch number 72\n",
            " -Training DS. Got 2691 out of 2870 images correctly (93.763%). Epoch  loss: 0.178\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 73\n",
            " -Training DS. Got 2688 out of 2870 images correctly (93.659%). Epoch  loss: 0.176\n",
            " -Testing DS. Got 835 out of 2870 images correctly (29.094%)\n",
            "Epoch number 74\n",
            " -Training DS. Got 2715 out of 2870 images correctly (94.599%). Epoch  loss: 0.152\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 75\n",
            " -Training DS. Got 2699 out of 2870 images correctly (94.042%). Epoch  loss: 0.168\n",
            " -Testing DS. Got 855 out of 2870 images correctly (29.791%)\n",
            "Epoch number 76\n",
            " -Training DS. Got 2700 out of 2870 images correctly (94.077%). Epoch  loss: 0.160\n",
            " -Testing DS. Got 827 out of 2870 images correctly (28.815%)\n",
            "Epoch number 77\n",
            " -Training DS. Got 2705 out of 2870 images correctly (94.251%). Epoch  loss: 0.167\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 78\n",
            " -Training DS. Got 2725 out of 2870 images correctly (94.948%). Epoch  loss: 0.158\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 79\n",
            " -Training DS. Got 2696 out of 2870 images correctly (93.937%). Epoch  loss: 0.168\n",
            " -Testing DS. Got 2509 out of 2870 images correctly (87.422%)\n",
            "Epoch number 80\n",
            " -Training DS. Got 2720 out of 2870 images correctly (94.774%). Epoch  loss: 0.154\n",
            " -Testing DS. Got 715 out of 2870 images correctly (24.913%)\n",
            "Epoch number 81\n",
            " -Training DS. Got 2711 out of 2870 images correctly (94.460%). Epoch  loss: 0.160\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 82\n",
            " -Training DS. Got 2667 out of 2870 images correctly (92.927%). Epoch  loss: 0.189\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 83\n",
            " -Training DS. Got 2690 out of 2870 images correctly (93.728%). Epoch  loss: 0.178\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 84\n",
            " -Training DS. Got 2719 out of 2870 images correctly (94.739%). Epoch  loss: 0.163\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 85\n",
            " -Training DS. Got 2689 out of 2870 images correctly (93.693%). Epoch  loss: 0.175\n",
            " -Testing DS. Got 823 out of 2870 images correctly (28.676%)\n",
            "Epoch number 86\n",
            " -Training DS. Got 2688 out of 2870 images correctly (93.659%). Epoch  loss: 0.184\n",
            " -Testing DS. Got 421 out of 2870 images correctly (14.669%)\n",
            "Epoch number 87\n",
            " -Training DS. Got 2740 out of 2870 images correctly (95.470%). Epoch  loss: 0.138\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 88\n",
            " -Training DS. Got 2710 out of 2870 images correctly (94.425%). Epoch  loss: 0.157\n",
            " -Testing DS. Got 862 out of 2870 images correctly (30.035%)\n",
            "Epoch number 89\n",
            " -Training DS. Got 2720 out of 2870 images correctly (94.774%). Epoch  loss: 0.147\n",
            " -Testing DS. Got 1112 out of 2870 images correctly (38.746%)\n",
            "Epoch number 90\n",
            " -Training DS. Got 2716 out of 2870 images correctly (94.634%). Epoch  loss: 0.155\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 91\n",
            " -Training DS. Got 2718 out of 2870 images correctly (94.704%). Epoch  loss: 0.142\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 92\n",
            " -Training DS. Got 2704 out of 2870 images correctly (94.216%). Epoch  loss: 0.155\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 93\n",
            " -Training DS. Got 2639 out of 2870 images correctly (91.951%). Epoch  loss: 0.218\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 94\n",
            " -Training DS. Got 2736 out of 2870 images correctly (95.331%). Epoch  loss: 0.142\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 95\n",
            " -Training DS. Got 2668 out of 2870 images correctly (92.962%). Epoch  loss: 0.183\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 96\n",
            " -Training DS. Got 2726 out of 2870 images correctly (94.983%). Epoch  loss: 0.155\n",
            " -Testing DS. Got 577 out of 2870 images correctly (20.105%)\n",
            "Epoch number 97\n",
            " -Training DS. Got 2701 out of 2870 images correctly (94.111%). Epoch  loss: 0.177\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 98\n",
            " -Training DS. Got 2684 out of 2870 images correctly (93.519%). Epoch  loss: 0.176\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 99\n",
            " -Training DS. Got 2684 out of 2870 images correctly (93.519%). Epoch  loss: 0.195\n",
            " -Testing DS. Got 549 out of 2870 images correctly (19.129%)\n",
            "Epoch number 100\n",
            " -Training DS. Got 2718 out of 2870 images correctly (94.704%). Epoch  loss: 0.157\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 101\n",
            " -Training DS. Got 2716 out of 2870 images correctly (94.634%). Epoch  loss: 0.147\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 102\n",
            " -Training DS. Got 2693 out of 2870 images correctly (93.833%). Epoch  loss: 0.172\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 103\n",
            " -Training DS. Got 2715 out of 2870 images correctly (94.599%). Epoch  loss: 0.169\n",
            " -Testing DS. Got 410 out of 2870 images correctly (14.286%)\n",
            "Epoch number 104\n",
            " -Training DS. Got 2697 out of 2870 images correctly (93.972%). Epoch  loss: 0.160\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 105\n",
            " -Training DS. Got 2692 out of 2870 images correctly (93.798%). Epoch  loss: 0.171\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 106\n",
            " -Training DS. Got 2734 out of 2870 images correctly (95.261%). Epoch  loss: 0.136\n",
            " -Testing DS. Got 652 out of 2870 images correctly (22.718%)\n",
            "Epoch number 107\n",
            " -Training DS. Got 2704 out of 2870 images correctly (94.216%). Epoch  loss: 0.169\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 108\n",
            " -Training DS. Got 2697 out of 2870 images correctly (93.972%). Epoch  loss: 0.171\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 109\n",
            " -Training DS. Got 2726 out of 2870 images correctly (94.983%). Epoch  loss: 0.143\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 110\n",
            " -Training DS. Got 2694 out of 2870 images correctly (93.868%). Epoch  loss: 0.170\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 111\n",
            " -Training DS. Got 2709 out of 2870 images correctly (94.390%). Epoch  loss: 0.163\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 112\n",
            " -Training DS. Got 2742 out of 2870 images correctly (95.540%). Epoch  loss: 0.136\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 113\n",
            " -Training DS. Got 2737 out of 2870 images correctly (95.366%). Epoch  loss: 0.143\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 114\n",
            " -Training DS. Got 2685 out of 2870 images correctly (93.554%). Epoch  loss: 0.189\n",
            " -Testing DS. Got 520 out of 2870 images correctly (18.118%)\n",
            "Epoch number 115\n",
            " -Training DS. Got 2680 out of 2870 images correctly (93.380%). Epoch  loss: 0.181\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 116\n",
            " -Training DS. Got 2726 out of 2870 images correctly (94.983%). Epoch  loss: 0.140\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 117\n",
            " -Training DS. Got 2700 out of 2870 images correctly (94.077%). Epoch  loss: 0.168\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 118\n",
            " -Training DS. Got 2718 out of 2870 images correctly (94.704%). Epoch  loss: 0.155\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 119\n",
            " -Training DS. Got 2704 out of 2870 images correctly (94.216%). Epoch  loss: 0.162\n",
            " -Testing DS. Got 676 out of 2870 images correctly (23.554%)\n",
            "Epoch number 120\n",
            " -Training DS. Got 2707 out of 2870 images correctly (94.321%). Epoch  loss: 0.164\n",
            " -Testing DS. Got 1295 out of 2870 images correctly (45.122%)\n",
            "Epoch number 121\n",
            " -Training DS. Got 2693 out of 2870 images correctly (93.833%). Epoch  loss: 0.177\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 122\n",
            " -Training DS. Got 2704 out of 2870 images correctly (94.216%). Epoch  loss: 0.167\n",
            " -Testing DS. Got 396 out of 2870 images correctly (13.798%)\n",
            "Epoch number 123\n",
            " -Training DS. Got 2700 out of 2870 images correctly (94.077%). Epoch  loss: 0.173\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 124\n",
            " -Training DS. Got 2704 out of 2870 images correctly (94.216%). Epoch  loss: 0.169\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 125\n",
            " -Training DS. Got 2709 out of 2870 images correctly (94.390%). Epoch  loss: 0.170\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 126\n",
            " -Training DS. Got 2705 out of 2870 images correctly (94.251%). Epoch  loss: 0.157\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 127\n",
            " -Training DS. Got 2697 out of 2870 images correctly (93.972%). Epoch  loss: 0.186\n",
            " -Testing DS. Got 392 out of 2870 images correctly (13.659%)\n",
            "Epoch number 128\n",
            " -Training DS. Got 2718 out of 2870 images correctly (94.704%). Epoch  loss: 0.155\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 129\n",
            " -Training DS. Got 2684 out of 2870 images correctly (93.519%). Epoch  loss: 0.180\n",
            " -Testing DS. Got 401 out of 2870 images correctly (13.972%)\n",
            "Epoch number 130\n",
            " -Training DS. Got 2720 out of 2870 images correctly (94.774%). Epoch  loss: 0.161\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 131\n",
            " -Training DS. Got 2683 out of 2870 images correctly (93.484%). Epoch  loss: 0.182\n",
            " -Testing DS. Got 400 out of 2870 images correctly (13.937%)\n",
            "Epoch number 132\n",
            " -Training DS. Got 2718 out of 2870 images correctly (94.704%). Epoch  loss: 0.157\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 133\n",
            " -Training DS. Got 2714 out of 2870 images correctly (94.564%). Epoch  loss: 0.154\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 134\n",
            " -Training DS. Got 2709 out of 2870 images correctly (94.390%). Epoch  loss: 0.155\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 135\n",
            " -Training DS. Got 2703 out of 2870 images correctly (94.181%). Epoch  loss: 0.168\n",
            " -Testing DS. Got 397 out of 2870 images correctly (13.833%)\n",
            "Epoch number 136\n",
            " -Training DS. Got 2701 out of 2870 images correctly (94.111%). Epoch  loss: 0.174\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 137\n",
            " -Training DS. Got 2720 out of 2870 images correctly (94.774%). Epoch  loss: 0.158\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 138\n",
            " -Training DS. Got 2697 out of 2870 images correctly (93.972%). Epoch  loss: 0.163\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 139\n",
            " -Training DS. Got 2701 out of 2870 images correctly (94.111%). Epoch  loss: 0.175\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 140\n",
            " -Training DS. Got 2694 out of 2870 images correctly (93.868%). Epoch  loss: 0.171\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 141\n",
            " -Training DS. Got 2715 out of 2870 images correctly (94.599%). Epoch  loss: 0.157\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 142\n",
            " -Training DS. Got 2747 out of 2870 images correctly (95.714%). Epoch  loss: 0.134\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 143\n",
            " -Training DS. Got 2689 out of 2870 images correctly (93.693%). Epoch  loss: 0.181\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 144\n",
            " -Training DS. Got 2706 out of 2870 images correctly (94.286%). Epoch  loss: 0.153\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 145\n",
            " -Training DS. Got 2698 out of 2870 images correctly (94.007%). Epoch  loss: 0.180\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 146\n",
            " -Training DS. Got 2747 out of 2870 images correctly (95.714%). Epoch  loss: 0.123\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 147\n",
            " -Training DS. Got 2741 out of 2870 images correctly (95.505%). Epoch  loss: 0.130\n",
            " -Testing DS. Got 429 out of 2870 images correctly (14.948%)\n",
            "Epoch number 148\n",
            " -Training DS. Got 2713 out of 2870 images correctly (94.530%). Epoch  loss: 0.167\n",
            " -Testing DS. Got 822 out of 2870 images correctly (28.641%)\n",
            "Epoch number 149\n",
            " -Training DS. Got 2710 out of 2870 images correctly (94.425%). Epoch  loss: 0.161\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Epoch number 150\n",
            " -Training DS. Got 2673 out of 2870 images correctly (93.136%). Epoch  loss: 0.188\n",
            " -Testing DS. Got 395 out of 2870 images correctly (13.763%)\n",
            "Finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_nn(resnet50_model,train_loader,test_loader,loss_fn,optimizer,150)"
      ],
      "id": "V6p9mYsZ_PJo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0b9ae08"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "d0b9ae08"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Resnet50+HSV",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}